// sme: MG, author: sduke?
= Migrating the Database Connector

// Explain generally how and why things changed between Mule 3 and Mule 4.
The Database connector for Mule 4 can connect to any relational Database engine. These are the main changes for Mule 4:

* Operations:
 ** Bulk Insert, Update, and Delete are now separate operations, so the XML for the related elements and attributes has changed significantly since Mule 4.
 ** Use of DataWeave: Insert and Update operations support DataWeave transformations. You can construct the data sets that insert or update the database without message side effects, and you no longer use message enrichers.
 ** Bulk functionality is extracted to its own set of operations, so operations that no longer change their behavior depending on the received payload.

* You can perform dynamic and static queries in about the same way.

* You can now embed DataWeave transformations inside the Insert and Update operations so that you can construct the data sets you want to send to the database without having a side effect on the message or using enrichers.

* The Mule streaming framework is automatically configured for your operations. You can execute a select statement and process the results asynchronously without worrying about leaking connections.

|===
| Operations in Mule 3 | Changes in Mule 4

| Bulk Execute (`db:bulk-execute`) | Bulk Delete (`db:bulk-delete`), Bulk Insert (`db:bulk-insert`), Bulk Update (`db:bulk-update`)

| DDL operations such as CREATE, ALTER, etc. | TODO?
|===

What's covered in this section:

* <<database_configuration>>
* <<database_operation_select>>
* <<database_dynamic_queries>>
* <<database_streaming>>
* <<database_insert_update_delete>>
* <<database_operation_bulk>>

[[database_configuration]]
== Database Configuration

// TODO: EXPLAIN CONFIG CHANGES?
The connector for Mule 4 still supports Derby, MySQL, Oracle, and a generic database configuration. However, the XML for configuring them has changed.

.Mule 3 Example: Configurations
----
<database:derby-config name="DerbyConfig"
 url="derbydatabase.com/MydatabaseTest"
 doc:name="Derby Configuration"/>
----

.Mule 4 Example: Derby Configuration
----
<database:config name="DerbyConfig" doc:name="Database Config">
  <database:derby-connection database="derbydatabase.com/MydatabaseTest" />
</database:config>
----

[[database_operation_select]]
== Select Operation

The Select operation retrieves information from the RDBMS. It takes an SQL query and uses DataWeave to supply the parameters.

.Mule 3 Example: SELECT
----
<flow name="selectParameterizedQuery">
    <db:select config-ref="Derby_Configuration" doc:name="Database" streaming="true">
        <db:parameterized-query>
          <!-- TODO: SHOW PARAMETERIZED INPUT-->
        </db:parameterized-query>
    </db:select>
</flow>
----

.Mule 4 Example: SELECT
----
<flow name="selectParameterizedQuery">
  <database:select config-ref="databaseConfig">
    <database:sql>select * from PLANET where name = :name</database:sql>
    <database:input-parameters>
      #[{'name' : payload}]
    </database:input-parameters>
  </database:select>
</flow>
----

As you can see in the Mule 4 example, input parameters are supplied as key-value pairs, which you can create by embedding a DataWeave script. Those keys are used in conjunction with the semicolon character (`:`) to reference to a parameter value by name. This is the recommended approach for using parameters in your query:

* The query becomes immune to SQL injection attacks.
* The connector can perform optimizations that are not possible otherwise, which improves the application’s overall performance.

[[database_dynamic_queries]]
== Dynamic Queries

Sometimes you not only need to parameterize the WHERE clause but also to parameterize parts of the query itself. Use cases for this include queries that need to hit online/historic tables depending on a condition, or complex queries where the project columns need to vary.

In Mule 3, the concept of SELECT was split in parameterized and dynamic queries, and you couldn’t use both at the same time. You had to choose between having a dynamic query or having the advantages of using parameters (SQL Injection protection, PreparedStatement optimization, and so on). Furthermore, the syntax to do one or the other was different, so you had to learn two different ways of doing the same thing.

.Mule 3 Example: SELECT with Parameterized Query
----
<db:select config-ref="databaseConfig" doc:name="Database">
    <db:parameterized-query/>
</db:update>
----

.Mule 3 Example: SELECT with Dynamic Query
----
<db:select config-ref="databaseConfig" doc:name="Database" >
    <db:dynamic-query/>
</db:select>
----

The Database Connector for Mule 4, can use both methods at the same time through expressions in the query. In the Mule 4 example, the expression produces the query by building a string in which the table depends on a variable. Notice that although the query text is dynamic, it still uses input parameters.

.Mule 4 Example
----
TODO: IS THIS OUT OF DATE? SEE BELOW?
<set-variable variableName="table" value="PLANET"/>
<database:select config-ref="databaseConfig">
 <database:sql>#["SELECT * FROM $(vars.table) WHERE name = :name"]</database:sql>
 <database:input-parameters>
   #[{'name' : payload}]
 </database:input-parameters>
</database:select>

// TODO: LOOKS LIKE THE ABOVE IS OUT OF DATE. THIS COMES FROM STUDIO 7.1.
// is it correct?:
<set-variable value="PLANET" doc:name="Set Variable" doc:id="9712c6fb-b9c2-4663-b3c7-d756c81f5444" variableName="table"/>
<db:select doc:name="Select" doc:id="9ea907ea-fd37-47b9-ad07-70c0521bac8d" config-ref="Database_Config">
  <db:sql >SELECT * FROM $(vars.table) WHERE name = :name</db:sql>
  <db:input-parameters ><![CDATA[{'name' : payload}]]></db:input-parameters>
</db:select>
----

You might ask why you need dynamic queries for the example above. You might wonder if you can treat the table like another Input Parameter? The answer is no. Input Parameters can only be applied to parameters in a WHERE clause. To modify any other part of the query, you need to use the DataWeave interpolation operator.

// TODO: SHOULD WE DISCUSS THE DW INTERPOLATION OPERATOR?

<<database_streaming>>
== Streaming Large Results

Database tables tend to be big. A single query might return tens of thousands of records, especially for integration use cases. Streaming is a great solution for this. What does streaming mean? Suppose you have a query which returns 10K rows. Attempting to fetch all those rows at once will result in the following:

* Performance degradation, since that’s a big pull from the network.
* A risk of running out of memory, since all that information needs to be loaded into RAM.

Streaming means that the connector will not fetch the 10K rows at once. Instead, it will fetch a smaller chunk, and once that chunk has been consumed it will fetch the rest. That way, you can reduce pressure over the network and memory.

In Mule 3.x this was something you had to specifically enable because it was disabled by default. In Mule 4, this is transparent and always enabled, you don’t have to worry about it anymore. You can simply trust that the feature is there.

.Mule 3 Example: Enabling Streaming
----
TODO: show streaming enabled
----

.Mule 4 Example: Streaming Automatically Enabled
----
TODO: show example of same process without setting for enabling streaming
----

// NOTE: WHAT'S BELOW IS NEW AND DOES NOT HAVE A MIGRATION IMPACT, SO PROB NOT NEEDED
Another improvement from Mule 3 is that you can now use the new repeatable streams mechanism from Mule 4. That means that streams are now repeatable, and you can make DataWeave and other components process the same stream many times, even in parallel.

[[database_insert_update_delete]]
== Insert, Update, and Delete Operations

The Insert, Update, and Delete operations also support the use of DataWeave parameters to get results from dynamic queries.

.Mule 4 Example: Insert with
----
<database:insert config-ref="databaseConfig">
  <database:sql>
    INSERT INTO PLANET(POSITION, NAME, DESCRIPTION) VALUES (777, 'Pluto', :description)
  </database:sql>
  <database:input-parameters>
    #[
    {'description' : payload}
    ]
  </database:input-parameters>
</database:insert>
----

.Mule 4 Example: Update
----
<database:update config-ref="databaseConfig">
  <database:sql>
    UPDATE PLANET SET DESCRIPTION = :description where POSITION = :position
  </database:sql>
  <database:input-parameters>
  #[
    {'description' : payload,
    'position' : 7,
    }
  ]
  </database:input-parameters>
</database:update>
----

.Mule 4 Example
----
<database:delete config-ref="databaseConfig">
  <database:sql>
    DELETE FROM PLANET where POSITION = :position
  </database:sql>
  <database:input-parameters>
  #[
    {'position' : 7}
  ]
  </database:input-parameters>
</database:delete>
----

[[database_operation_bulk]]
== Bulk Operations

The Insert, Update, and Delete operations above are fine for the cases in which each input parameter can take only one value.

For example, when deleting, many rows might match the criteria and get deleted, but only one criterion (`POSITION = X`) is provided. The same concept applies for Update. That is, if you run `UPDATE PRODUCTS set PRICE = PRICE * 0.9 where PRICE > :price`, you might be applying a 10% discount on many products, but the `price` input parameter will only take one value. To apply _different_ discount rates on products that have different prices, you can either execute many operations, or can use the Bulk operation.

For example, assume you have a payload that is a list of objects of the following structure: `{ price : number, discountRate: number}`. You can execute many operations like this:

.Mule 4 Example: Executing Many Operations to Get Different Values
----
<foreach>
  <database:update config-ref="databaseConfig">
    <database:sql>
      UPDATE PRODUCTS set PRICE = PRICE * :discountRate where PRICE > :price
    </database:sql>
    <database:input-parameters>
     #[
      {
        'discountRate' : payload.discountRate,
        'price' : payload.price,
      }
    ]
    </database:input-parameters>
  </database:update>
</foreach>
----

Though the approach above works, it is inefficient because the query needs to be executed for each element in the list. For each element, you have to do this:

* Parse the query.
* Resolve parameters.
* Get a connection to the database (either by getting one for the pool or establishing a new one).
* Pay all the network overhead.
* The RBMS has to process the query and apply changes.
* Release the connection.

You can avoid that inefficiency with a Bulk operation. In the example above, the UPDATE statement is constant, not dynamic. The only thing that changes is that each iteration supplies a different set of parameters.

Bulk operations allow you to run a single query using a set of parameters values. Make no mistake though, this is not just a shortcut for the same `<foreach>` above. This uses features on the JdatabaseC API so that:

* The query is parsed only once.
* Only one database connection is required since a single statement is executed.
* Network overhead is minimized.
* RBDMS can execute the bulk operation atomically.

For these use cases, the connector offers three operations, `<bulk-insert>`, `<bulk-update>`, and `<bulk-delete>`.

These are similar to their single counterparts, except that instead of receiving input parameters as key-value pairs, they expect them as a list of key-value pairs.

.Mule 4 Example: Using the Bulk Operation to Get Different Values
----
<database:bulk-insert config-ref="databaseConfig" >
  <database:sql>
    insert into customers (id, name, lastName) values (:id, :name, :lastName)
  </database:sql>
  <database:bulk-input-parameters>
    #[[{'id': 2, 'name': 'George', 'lastName': 'Costanza'}, {'id': 3, 'name': 'Cosmo', 'lastName': 'Kramer'}]]
  </database:bulk-input-parameters>
</database:bulk-insert>
----

////
== TODO/NOTE: Other Topics Discussed in the Spec

QUESTION: SHOULD WE cover any of these?

spec here: https://docs.google.com/document/d/1zQLrSomGj8C5S7N5FDIVk1ThPiXTOWO9LVbxfSxjFAo/edit#heading=h.z8xftz3l7kjd

* Pooling Profile?
* Connections
  - Generic JdatabaseC connection
  - Global DataSource reference connection
  - Connection Types: MySQL, Derby, Oracle
  - Common Connection Parameters?
* Parameter Types
* Stored Procedure
////

////

[[database_connection_pooling]]
== Connection Pooling

Pooling configuration for JdatabaseC Data Sources is capable of pooling connections. Note that this profile is targeted at data sources and is not the standard pooling profile used by other connectors.

.Mule 3 Example
----
TODO
----

.Mule 4 Example
----
TODO
----
////


== See Also

link:migration-examples[Migration Examples]

link:migration-patterns[Migration Patterns]

link:migration-components[Migrating Components]
